{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dYKpezSN4lA",
        "outputId": "1d07975a-29a3-4512-ab60-6eaad4b12fbd"
      },
      "outputs": [],
      "source": [
        "# IMDB Text Classification using TensorFlow\n",
        "\n",
        "# Step 1: Import Libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "\n",
        "# Step 2: Load the IMDb Dataset\n",
        "num_words = 10000  # Only use top 10,000 most frequent words\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=num_words)\n",
        "\n",
        "print(f\"Training samples: {len(x_train)}, Testing samples: {len(x_test)}\")\n",
        "\n",
        "# Step 3: Preprocess the Data (Padding sequences)\n",
        "maxlen = 500  # Max review length\n",
        "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = pad_sequences(x_test, maxlen=maxlen)\n",
        "\n",
        "print(\"Sample (padded) review:\", x_train[0])\n",
        "\n",
        "# Step 4: Build the Model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=num_words, output_dim=32, input_length=maxlen),\n",
        "    LSTM(64),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Step 5: Compile the Model\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Step 6: Train the Model\n",
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    epochs=5,\n",
        "    batch_size=64,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "# Step 7: Evaluate the Model\n",
        "loss, accuracy = model.evaluate(x_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Step 8: Make Predictions\n",
        "predictions = model.predict(x_test[:5])\n",
        "print(\"Predicted probabilities:\", predictions.flatten())\n",
        "print(\"Actual labels:\", y_test[:5])\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
