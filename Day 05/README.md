# ðŸ“˜ Day 05: Math for Machine Learning

## ðŸ§  Objective
Develop a solid understanding of the **mathematics that underpin machine learning algorithms**. By the end of the day, youâ€™ll be able to confidently understand the concepts that guide models behind the scenes.

---

## ðŸ“Œ Topics Covered

### ðŸ“ Linear Algebra
- Vectors, matrices, dot product, matrix multiplication
- Transpose, identity matrix
- Matrix-vector multiplication in ML (e.g., XÂ·W + b)

### ðŸ” Calculus
- Derivatives & partial derivatives
- Gradients & gradient descent
- Visualization of a loss surface and gradient steps

### ðŸŽ² Probability & Statistics
- Mean, variance, standard deviation
- Bayes' Theorem, probability distributions
- Normal distribution, Bernoulli, binomial (introduction)

### âš™ï¸ Optimization
- Cost function
- Gradient descent: concept and visualization

---

## ðŸ’» Hands-On Practice
- [ ] Visualize vectors and matrix multiplication using NumPy
- [ ] Simulate normal distributions and compute stats with Python
- [ ] Animate gradient descent steps for a quadratic function
- [ ] Manually compute gradients and compare with `sympy` or `autograd`

---

## ðŸ”— Resources
- [Essence of Linear Algebra (3Blue1Brown)](https://www.youtube.com/playlist?list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr)
- [Khan Academy - Intro to Calculus](https://www.khanacademy.org/math/calculus-1)
- [StatQuest - ML Math](https://www.youtube.com/c/joshstarmer)
- [Python NumPy Guide](https://numpy.org/doc/)

---

## âœ… Challenge
- Derive the gradient of the Mean Squared Error loss
- Simulate a dataset and apply linear regression from scratch using math
- Visualize the cost function for a regression problem

---

> âœ¨ A strong math foundation helps you go beyond using ML â€” it helps you **understand it**.
